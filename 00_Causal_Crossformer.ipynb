{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aaaeca6-4fe6-455d-b0e3-09283b0e7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, matthews_corrcoef, roc_auc_score, precision_recall_curve, auc\n",
    "import os\n",
    "import random\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c82490-beea-4fd6-b2c9-f10929b50443",
   "metadata": {},
   "source": [
    "## old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d086cc08-8104-4207-9379-c8107bafd358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from einops import rearrange, repeat\n",
    "# import math\n",
    "\n",
    "\n",
    "# class DSW_embedding(nn.Module):\n",
    "#     def __init__(self, seg_len, d_model):\n",
    "#         super(DSW_embedding, self).__init__()\n",
    "#         self.seg_len = seg_len\n",
    "#         self.d_model = d_model\n",
    "#         self.linear = nn.Linear(seg_len * 231, d_model)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch, ts_len, ts_dim = x.shape\n",
    "#         pad_len = (self.seg_len - (ts_len % self.seg_len)) % self.seg_len\n",
    "#         if pad_len != 0:\n",
    "#             x = torch.cat([x, torch.zeros(batch, pad_len, ts_dim).to(x.device)], dim=1)\n",
    "#         seg_num = (ts_len + pad_len) // self.seg_len\n",
    "#         x_segment = rearrange(x, 'b (seg_num seg_len) d -> b seg_num (seg_len d)', seg_len=self.seg_len)\n",
    "#         x_embed = self.linear(x_segment)\n",
    "#         # Reshape to (batch, seg_num * seg_len, d_model)\n",
    "#         x_embed = x_embed.unsqueeze(2).repeat(1, 1, self.seg_len, 1)\n",
    "#         x_embed = x_embed.view(batch, -1, self.d_model)\n",
    "#         return x_embed[:, :ts_len, :]  # Remove the padding\n",
    "\n",
    "# class SegMerging(nn.Module):\n",
    "#     def __init__(self, d_model, win_size, norm_layer=nn.LayerNorm):\n",
    "#         super().__init__()\n",
    "#         self.d_model = d_model\n",
    "#         self.win_size = win_size\n",
    "#         self.linear_trans = nn.Linear(d_model, d_model)\n",
    "#         self.norm = norm_layer(d_model)\n",
    "\n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         x = self.norm(x)\n",
    "#         x = self.linear_trans(x)\n",
    "#         return x\n",
    "\n",
    "# class AttentionLayer(nn.Module):\n",
    "#     def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "#         super(AttentionLayer, self).__init__()\n",
    "#         self.n_heads = n_heads\n",
    "#         self.d_model = d_model\n",
    "#         self.d_k = d_model // n_heads\n",
    "\n",
    "#         self.qkv_proj = nn.Linear(d_model, 3 * d_model)\n",
    "#         self.o_proj = nn.Linear(d_model, d_model)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#     def forward(self, q, k, v):\n",
    "#         B, L, _ = q.size()\n",
    "#         qkv = self.qkv_proj(q).chunk(3, dim=-1)\n",
    "#         q, k, v = [rearrange(x, 'b l (h d) -> b h l d', h=self.n_heads) for x in qkv]\n",
    "\n",
    "#         scores = torch.einsum('bhld,bhmd->bhlm', q, k) / math.sqrt(self.d_k)\n",
    "#         attn = scores.softmax(dim=-1)\n",
    "#         attn = self.dropout(attn)\n",
    "\n",
    "#         context = torch.einsum('bhlm,bhmd->bhld', attn, v)\n",
    "#         context = rearrange(context, 'b h l d -> b l (h d)')\n",
    "#         output = self.o_proj(context)\n",
    "#         return output\n",
    "\n",
    "# class CrossEncoder(nn.Module):\n",
    "#     def __init__(self, d_model, n_heads, d_ff, block_depth, dropout, factor, e_blocks, win_size):\n",
    "#         super().__init__()\n",
    "#         self.time_attention = AttentionLayer(d_model, n_heads, dropout)\n",
    "#         self.dim_sender = AttentionLayer(d_model, n_heads, dropout)\n",
    "#         self.dim_receiver = AttentionLayer(d_model, n_heads, dropout)\n",
    "#         self.router = nn.Parameter(torch.randn(e_blocks, factor, d_model))\n",
    "        \n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.norm1 = nn.LayerNorm(d_model)\n",
    "#         self.norm2 = nn.LayerNorm(d_model)\n",
    "#         self.norm3 = nn.LayerNorm(d_model)\n",
    "#         self.norm4 = nn.LayerNorm(d_model)\n",
    "        \n",
    "#         self.MLP1 = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "#                                   nn.GELU(),\n",
    "#                                   nn.Linear(d_ff, d_model))\n",
    "#         self.MLP2 = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "#                                   nn.GELU(),\n",
    "#                                   nn.Linear(d_ff, d_model))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch, seq_len, d_model = x.shape\n",
    "#         time_enc = self.time_attention(x, x, x)\n",
    "#         dim_in = x + self.dropout(time_enc)\n",
    "#         dim_in = self.norm1(dim_in)\n",
    "#         dim_in = dim_in + self.dropout(self.MLP1(dim_in))\n",
    "#         dim_in = self.norm2(dim_in)\n",
    "\n",
    "#         dim_send = dim_in\n",
    "#         batch_router = repeat(self.router, 'e_blocks factor d_model -> (repeat e_blocks) factor d_model', repeat=batch)\n",
    "#         dim_buffer = self.dim_sender(batch_router, dim_send, dim_send)\n",
    "#         dim_receive = self.dim_receiver(dim_send, dim_buffer, dim_buffer)\n",
    "#         dim_enc = dim_send + self.dropout(dim_receive)\n",
    "#         dim_enc = self.norm3(dim_enc)\n",
    "#         dim_enc = dim_enc + self.dropout(self.MLP2(dim_enc))\n",
    "#         dim_enc = self.norm4(dim_enc)\n",
    "\n",
    "#         return dim_enc\n",
    "\n",
    "# class EncoderOnlyCrossFormer(nn.Module):\n",
    "#     def __init__(self, seg_len, d_model, num_classes, num_layers, win_size, n_heads, d_ff, e_blocks, dropout=0.1):\n",
    "#         super(EncoderOnlyCrossFormer, self).__init__()\n",
    "        \n",
    "#         # Embedding layer\n",
    "#         self.embedding = DSW_embedding(seg_len, d_model)\n",
    "        \n",
    "#         # Encoder layers\n",
    "#         self.encoders = nn.ModuleList([\n",
    "#             CrossEncoder(d_model=d_model, n_heads=n_heads, d_ff=d_ff, block_depth=1, dropout=dropout, factor=5, e_blocks=e_blocks, win_size=win_size) for _ in range(num_layers)\n",
    "#         ])\n",
    "        \n",
    "#         # Segment merging layer\n",
    "#         self.seg_merge = SegMerging(d_model, win_size)\n",
    "        \n",
    "#         # Classification head\n",
    "#         self.logit = nn.Linear(d_model, num_classes)\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.LayerNorm(d_model),\n",
    "#             self.logit\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # Apply embedding\n",
    "#         x_embed = self.embedding(x)\n",
    "        \n",
    "#         # Pass through each encoder layer\n",
    "#         for encoder in self.encoders:\n",
    "#             x_embed = encoder(x_embed)\n",
    "        \n",
    "#         # Merge segments\n",
    "#         x_merged = self.seg_merge(x_embed)\n",
    "        \n",
    "#         # Classification head\n",
    "#         logits = self.classifier(x_merged)\n",
    "        \n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c81445bf-4475-4b7c-8fe1-ced2ac198d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = EncoderOnlyCrossFormer(seg_len=1, d_model=36, num_classes=2, num_layers=1, win_size=1, n_heads=2, d_ff=16, e_blocks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e59ad66-9cf2-4977-be06-fb7a31ca8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c38729a-832e-44f6-95ba-26370bd24182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = torch.rand(1,2016, 231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf35535-411a-4685-ba67-db36e9e270d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38dc9298-fb48-4210-8cb0-f33e2698c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9af40184-13eb-45b0-8ff9-fc9631af171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = model_1(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49178307-4eea-497a-9ff9-dbc11a0fd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f4c7d74-9e8c-4ae6-87a9-4d01cb924153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a06722-2504-4efa-8547-9806c345d45b",
   "metadata": {},
   "source": [
    "### now causal crossformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa4e5ae9-43ba-4011-bea7-870637512452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "import math\n",
    "\n",
    "\n",
    "class DSW_embedding(nn.Module):\n",
    "    def __init__(self, seg_len, d_model):\n",
    "        super(DSW_embedding, self).__init__()\n",
    "        self.seg_len = seg_len\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(seg_len * 231, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, ts_len, ts_dim = x.shape\n",
    "        pad_len = (self.seg_len - (ts_len % self.seg_len)) % self.seg_len\n",
    "        if pad_len != 0:\n",
    "            x = torch.cat([x, torch.zeros(batch, pad_len, ts_dim).to(x.device)], dim=1)\n",
    "        seg_num = (ts_len + pad_len) // self.seg_len\n",
    "        x_segment = rearrange(x, 'b (seg_num seg_len) d -> b seg_num (seg_len d)', seg_len=self.seg_len)\n",
    "        x_embed = self.linear(x_segment)\n",
    "        x_embed = x_embed.unsqueeze(2).repeat(1, 1, self.seg_len, 1)\n",
    "        x_embed = x_embed.view(batch, -1, self.d_model)\n",
    "        return x_embed[:, :ts_len, :]\n",
    "\n",
    "\n",
    "class SegMerging(nn.Module):\n",
    "    def __init__(self, d_model, win_size, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.win_size = win_size\n",
    "        self.linear_trans = nn.Linear(d_model, d_model)\n",
    "        self.norm = norm_layer(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        x = self.linear_trans(x)\n",
    "        return x\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // n_heads\n",
    "\n",
    "        self.qkv_proj = nn.Linear(d_model, 3 * d_model)\n",
    "        self.o_proj = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        B, Lq, _ = q.size()\n",
    "        _, Lk, _ = k.size()\n",
    "\n",
    "        qkv = self.qkv_proj(q).chunk(3, dim=-1)\n",
    "        q, k, v = [rearrange(x, 'b l (h d) -> b h l d', h=self.n_heads) for x in qkv]\n",
    "\n",
    "        scores = torch.einsum('bhqd,bhkd->bhqk', q, k) / math.sqrt(self.d_k)\n",
    "\n",
    "        if Lq == Lk:\n",
    "            causal_mask = torch.tril(torch.ones(Lq, Lk, device=q.device)).unsqueeze(0).unsqueeze(0)\n",
    "            scores = scores.masked_fill(causal_mask == 0, float('-inf'))\n",
    "\n",
    "        attn = self.dropout(scores.softmax(dim=-1))\n",
    "\n",
    "        context = torch.einsum('bhqk,bhkd->bhqd', attn, v)\n",
    "        context = rearrange(context, 'b h l d -> b l (h d)')\n",
    "        return self.o_proj(context)\n",
    "\n",
    "class CrossEncoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout, factor, e_blocks):\n",
    "        super().__init__()\n",
    "        self.time_attention = AttentionLayer(d_model, n_heads, dropout)\n",
    "        self.dim_sender = AttentionLayer(d_model, n_heads, dropout)\n",
    "        self.dim_receiver = AttentionLayer(d_model, n_heads, dropout)\n",
    "\n",
    "        self.router = nn.Parameter(torch.randn(e_blocks, factor, d_model))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.norm4 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.MLP1 = nn.Sequential(nn.Linear(d_model, d_ff), nn.GELU(), nn.Linear(d_ff, d_model))\n",
    "        self.MLP2 = nn.Sequential(nn.Linear(d_model, d_ff), nn.GELU(), nn.Linear(d_ff, d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        time_enc = self.time_attention(x, x, x)\n",
    "        x = x + self.dropout(time_enc)\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.dropout(self.MLP1(x))\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        batch_router = repeat(self.router, 'e_blocks factor d_model -> (repeat e_blocks) factor d_model', repeat=x.size(0))\n",
    "\n",
    "        dim_buffer = self.dim_sender(batch_router, x, x)\n",
    "        dim_receive = self.dim_receiver(x, dim_buffer, dim_buffer)\n",
    "\n",
    "        x = x + self.dropout(dim_receive)\n",
    "        x = self.norm3(x)\n",
    "        x = x + self.dropout(self.MLP2(x))\n",
    "        x = self.norm4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class EncoderOnlyCrossFormer(nn.Module):\n",
    "    def __init__(self, seg_len, d_model, num_classes, num_layers, n_heads, d_ff, e_blocks, dropout=0.1, win_size=1):\n",
    "        super().__init__()\n",
    "        self.embedding = DSW_embedding(seg_len, d_model)\n",
    "        \n",
    "        self.encoders = nn.ModuleList([\n",
    "            CrossEncoder(d_model, n_heads, d_ff, dropout, factor=5, e_blocks=e_blocks)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Include the segment merging layer\n",
    "        self.seg_merge = SegMerging(d_model, win_size)\n",
    "        \n",
    "        # Classification head structure as in the original model\n",
    "        self.logit = nn.Linear(d_model, num_classes)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            self.logit\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.embedding(x)\n",
    "\n",
    "        for encoder in self.encoders:\n",
    "            x_embed = encoder(x_embed)\n",
    "\n",
    "        # segment merging (required for compatibility)\n",
    "        x_merged = self.seg_merge(x_embed)\n",
    "\n",
    "        logits = self.classifier(x_merged)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d475c04-0019-4bf8-a53f-e99de7e5fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = EncoderOnlyCrossFormer(seg_len=1, d_model=36, num_classes=2, num_layers=1, n_heads=2, d_ff=16, e_blocks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e47a4ab-19c9-4cd9-a3bb-47f0270f70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6b82e44-fdcc-4a5d-8753-30e224613773",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.rand(1,2016, 231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c16992fd-5c9c-4d37-b99f-0477a0be352a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2016, 231])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e5ef317-f633-4e7a-8f80-88e30194d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model_1(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfcb26ab-d16e-4c8b-b094-2ca36b11a6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0480, -0.6035],\n",
       "         [ 0.1179, -0.1640],\n",
       "         [ 0.2247, -0.2564],\n",
       "         ...,\n",
       "         [ 0.3353,  0.3213],\n",
       "         [ 0.6664,  0.1096],\n",
       "         [ 0.5011, -0.3630]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e9a5d75-9524-45cc-b3aa-63d6a44f6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warnings from PyTorch\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "torch.set_printoptions(profile=\"default\")  # Prevent any potential printing-related warnings\n",
    "import logging\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"pytorch_lightning.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "\n",
    "# Suppress TensorFlow logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "# Suppress Python warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6befa53b-aaad-4357-b627-b298395e5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'Crossformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93d19c5c-58f6-434e-af6a-c5f08f2739f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_1 = 'circ_crossformer/testing_Crossformer_Circ_seed_0/model_epoch_40.pth' #model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d6ea712-42fb-47d4-b08b-c5b1084eae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = torch.load(model_path_1)\n",
    "# Extract the model state dictionary\n",
    "model_state_dict = temp_model['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84d68d9e-4ba1-4e79-825a-dc8a23a034e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd2f6c-f9ba-4524-aa95-4442ab5841ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
